filename log/cola.pepg.4.128.best.json
model size 975
cola_started
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
loading file log/cola.pepg.4.128.best.json
0 [0.3672525239244635]
1 [0.3495179924062641]
2 [0.3601205860424758]
3 [0.356022391716307]
4 [0.34747990600757334]
5 [0.35020484462240564]
6 [0.3529413913168867]
7 [0.35260122344025346]
8 [0.35534121492676707]
9 [0.3491383236462536]
10 [0.3498360474690174]
11 [0.3470837793152221]
12 [0.36469290590130815]
13 [0.35050095263882064]
14 [0.3538892521794698]
15 [0.35815925422237943]
16 [0.3498436001366076]
17 [0.3477800431625565]
18 [0.3608325309110956]
19 [0.35020201775233195]
20 [0.34481058684719956]
21 [0.3453215589589493]
22 [0.3498816864222824]
23 [0.37168716620280495]
24 [0.3553504870571165]
25 [0.3635969000007344]
26 [0.3502020177523319]
27 [0.35360114254111225]
28 [0.34867196095141756]
29 [0.35190970236955166]
30 [0.3522425494924303]
31 [0.36258200374333566]
32 [0.35327898714694966]
33 [0.3508419342979992]
34 [0.34673712523378425]
35 [0.37094871316711936]
36 [0.3491840067203468]
37 [0.3450911493653515]
38 [0.35671307375791855]
39 [0.3536492374179793]
40 [0.33800570955719916]
41 [0.3666490973272865]
42 [0.35020201775233184]
43 [0.3577445026446145]
44 [0.363253398009722]
45 [0.3471165105320855]
46 [0.35229666438101487]
47 [0.35461532673445717]
48 [0.36083253091109596]
49 [0.3536011425411123]
50 [0.35258815287705947]
51 [0.3526062621449248]
52 [0.3556503081221324]
53 [0.34818705134310085]
54 [0.3423527202633645]
55 [0.3473816830143972]
56 [0.3457594167571486]
57 [0.3543078881960218]
58 [0.3622124736370188]
59 [0.36258200374333555]
60 [0.35842499822329127]
61 [0.33755589888037335]
62 [0.35266562449983135]
63 [0.3574130558997705]
64 [0.3601712932669286]
65 [0.36150347206659333]
66 [0.35331723223063083]
67 [0.3519327654524499]
68 [0.35258815287705964]
69 [0.35129515668107375]
70 [0.34946926115601806]
71 [0.35388925217946987]
72 [0.35224254949243033]
73 [0.3577479737510765]
74 [0.3670800255727642]
75 [0.36706526987127946]
76 [0.3652460176167437]
77 [0.350204844622406]
78 [0.35020484462240564]
79 [0.3563054708754132]
80 [0.35790786402832864]
81 [0.3618000330340394]
82 [0.3489507050859103]
83 [0.3508367355110586]
84 [0.3466713459650989]
85 [0.3448832775032744]
86 [0.35951997496878757]
87 [0.3660153177421655]
88 [0.35431764896699525]
89 [0.36457360956773566]
90 [0.34984881618847724]
91 [0.3494511733207319]
92 [0.35498461335140086]
93 [0.35608008304570476]
94 [0.36050001860038694]
95 [0.35087810225688065]
96 [0.3522425494924305]
97 [0.35498461335140086]
98 [0.3532394141545023]
99 [0.34362183883591646]
seed 0 average_reward 0.3540531852648383 standard_deviation 0.006758484734378038
