
/home/students/innes/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11050). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)
  return torch._C._cuda_getDeviceCount() > 0
size of model 514
cuda available? False
We are executing on: cpu
('Backpropagation optimization started',)
EPOCH 1:
slurmstepd-gpu08: error: *** JOB 371068 ON gpu08 CANCELLED AT 2023-12-28T19:11:45 ***
  batch 64 loss: 0.48009084770455956 corr: 0.76953125
  batch 128 loss: 0.31150125339627266 corr: 0.87158203125
  batch 192 loss: 0.2748586762463674 corr: 0.890625
  batch 256 loss: 0.250870258314535 corr: 0.89892578125
  batch 320 loss: 0.24138597573619336 corr: 0.90283203125
  batch 384 loss: 0.24910310609266162 corr: 0.90087890625
  batch 448 loss: 0.22161902935476974 corr: 0.91552734375
  batch 512 loss: 0.2185394822154194 corr: 0.90869140625
  batch 576 loss: 0.20887746947119012 corr: 0.91650390625
  batch 640 loss: 0.19512960530119017 corr: 0.92431640625
  batch 704 loss: 0.19712927035288885 corr: 0.92138671875
  batch 768 loss: 0.2131554951192811 corr: 0.9150390625
  batch 832 loss: 0.18048809515312314 corr: 0.9287109375
  batch 896 loss: 0.1954660172923468 corr: 0.9189453125
  batch 960 loss: 0.17722349666291848 corr: 0.93408203125
  batch 1024 loss: 0.1947459004004486 corr: 0.927734375
  batch 1088 loss: 0.1910861506476067 corr: 0.9296875
  batch 1152 loss: 0.17355755349854007 corr: 0.93603515625
  batch 1216 loss: 0.17988793266704306 corr: 0.93603515625
  batch 1280 loss: 0.15458581718849018 corr: 0.935546875
  batch 1344 loss: 0.17524218087783083 corr: 0.93359375
  batch 1408 loss: 0.15487195370951667 corr: 0.94580078125
  batch 1472 loss: 0.1565903956652619 corr: 0.94287109375
  batch 1536 loss: 0.14368122222367674 corr: 0.9423828125
  batch 1600 loss: 0.16245269085629843 corr: 0.94091796875
  batch 1664 loss: 0.16334308305522427 corr: 0.93359375
  batch 1728 loss: 0.1558359279006254 corr: 0.943359375
  batch 1792 loss: 0.16684865282149985 corr: 0.9423828125
  batch 1856 loss: 0.1654328797594644 corr: 0.94091796875
  batch 1920 loss: 0.15563571444363333 corr: 0.94091796875
  batch 1984 loss: 0.15814656112343073 corr: 0.93896484375
  batch 2048 loss: 0.14806352608138695 corr: 0.9462890625
LOSS train 0.19505394687190333 valid 0.21082261204719543
MATTHEW CORRELATION train 0.8961401425178147 valid 0.9263392857142857
EPOCH 2:
  batch 64 loss: 0.08867595538322348 corr: 0.96923828125
  batch 128 loss: 0.09569486382679315 corr: 0.96826171875
  batch 192 loss: 0.09483447177626658 corr: 0.9677734375
  batch 256 loss: 0.08399796507728752 corr: 0.96826171875
  batch 320 loss: 0.08564125494012842 corr: 0.97265625
  batch 384 loss: 0.11319949589960743 corr: 0.9638671875
  batch 448 loss: 0.10671297908993438 corr: 0.96142578125
  batch 512 loss: 0.11002573181758635 corr: 0.96142578125
  batch 576 loss: 0.09163637993333396 corr: 0.96630859375
  batch 640 loss: 0.08603075075370725 corr: 0.97021484375
  batch 704 loss: 0.10524435482511763 corr: 0.96484375
  batch 768 loss: 0.12670381605857983 corr: 0.95947265625
  batch 832 loss: 0.09764617010660004 corr: 0.96533203125
  batch 896 loss: 0.10266411534394138 corr: 0.96337890625
  batch 960 loss: 0.09115844167536125 corr: 0.966796875
  batch 1024 loss: 0.12182525402749889 corr: 0.95703125
  batch 1088 loss: 0.1155117473390419 corr: 0.9609375
  batch 1152 loss: 0.11423804880178068 corr: 0.9580078125
  batch 1216 loss: 0.09680144327285234 corr: 0.966796875
  batch 1280 loss: 0.09013457171386108 corr: 0.96630859375
  batch 1344 loss: 0.08568138544796966 corr: 0.9677734375
  batch 1408 loss: 0.11185072845546529 corr: 0.96044921875
  batch 1472 loss: 0.10756491812935565 corr: 0.96337890625
  batch 1536 loss: 0.09134969145816285 corr: 0.970703125
  batch 1600 loss: 0.11248616194643546 corr: 0.9619140625
  batch 1664 loss: 0.10945204805466346 corr: 0.95947265625
  batch 1728 loss: 0.09482130083779339 corr: 0.96728515625
  batch 1792 loss: 0.09512075054226443 corr: 0.96435546875
  batch 1856 loss: 0.10726571521809092 corr: 0.9619140625
  batch 1920 loss: 0.1227610083296895 corr: 0.9541015625
  batch 1984 loss: 0.13649467146024108 corr: 0.95263671875
  batch 2048 loss: 0.11373824183829129 corr: 0.95947265625
LOSS train 0.10054428681063149 valid 0.23056460916996002
MATTHEW CORRELATION train 0.93770783847981 valid 0.9241071428571429
EPOCH 3:
  batch 64 loss: 0.06349154567578807 corr: 0.97705078125
  batch 128 loss: 0.04999298757320503 corr: 0.984375
  batch 192 loss: 0.06358376227581175 corr: 0.978515625
  batch 256 loss: 0.06285214543095208 corr: 0.978515625
  batch 320 loss: 0.07067457396624377 corr: 0.978515625
  batch 384 loss: 0.05314717135479441 corr: 0.98095703125
  batch 448 loss: 0.07636743393959478 corr: 0.97314453125
  batch 512 loss: 0.07300190749083413 corr: 0.97412109375
  batch 576 loss: 0.07196055515305488 corr: 0.9765625
  batch 640 loss: 0.04975597877637483 corr: 0.98486328125
  batch 704 loss: 0.05599412463561748 corr: 0.98095703125
  batch 768 loss: 0.079200051164662 corr: 0.97705078125
  batch 832 loss: 0.07417428046755958 corr: 0.97412109375
  batch 896 loss: 0.06481967290892499 corr: 0.974609375
  batch 960 loss: 0.0728557457041461 corr: 0.97314453125
  batch 1024 loss: 0.06992264960717876 corr: 0.9794921875
  batch 1088 loss: 0.07394136086804792 corr: 0.9736328125
  batch 1152 loss: 0.054000650394300465 corr: 0.98193359375
  batch 1216 loss: 0.0734528547473019 corr: 0.97021484375
  batch 1280 loss: 0.06299898755241884 corr: 0.97607421875
  batch 1344 loss: 0.06540756241156487 corr: 0.97802734375
  batch 1408 loss: 0.07000225240335567 corr: 0.978515625
  batch 1472 loss: 0.0775521379764541 corr: 0.974609375
  batch 1536 loss: 0.06298259671166306 corr: 0.9775390625
  batch 1600 loss: 0.06804293256573146 corr: 0.97607421875
  batch 1664 loss: 0.07210701677104225 corr: 0.9765625
  batch 1728 loss: 0.09406585828401148 corr: 0.97265625
  batch 1792 loss: 0.08504674570576753 corr: 0.966796875
  batch 1856 loss: 0.0640260079599102 corr: 0.974609375
  batch 1920 loss: 0.08628861528995913 corr: 0.970703125
  batch 1984 loss: 0.07601208207051968 corr: 0.97119140625
  batch 2048 loss: 0.083422798794345 corr: 0.966796875
LOSS train 0.06753125082393953 valid 0.22237348556518555
MATTHEW CORRELATION train 0.9495694774346793 valid 0.9274553571428571
EPOCH 4:
  batch 64 loss: 0.0374055771590065 corr: 0.9892578125
  batch 128 loss: 0.053880754619967774 corr: 0.982421875
  batch 192 loss: 0.03487494399450952 corr: 0.98974609375
  batch 256 loss: 0.04562198870371503 corr: 0.9873046875
  batch 320 loss: 0.03432212362622522 corr: 0.9873046875
  batch 384 loss: 0.042676890689108404 corr: 0.98583984375
  batch 448 loss: 0.040083839547151 corr: 0.986328125
  batch 512 loss: 0.04143988028408785 corr: 0.98779296875
  batch 576 loss: 0.041641634477855405 corr: 0.98583984375
  batch 640 loss: 0.039138143465606845 corr: 0.98486328125
  batch 704 loss: 0.058660360607973416 corr: 0.97607421875
  batch 768 loss: 0.04570787303237012 corr: 0.9814453125
  batch 832 loss: 0.05666705122257554 corr: 0.98046875
  batch 896 loss: 0.03593765297955542 corr: 0.98876953125
  batch 960 loss: 0.04558415521751158 corr: 0.98388671875
  batch 1024 loss: 0.05879822036331461 corr: 0.98486328125
  batch 1088 loss: 0.05566878890749649 corr: 0.982421875
  batch 1152 loss: 0.054381665569962934 corr: 0.97705078125
  batch 1216 loss: 0.049567868723897845 corr: 0.9814453125
  batch 1280 loss: 0.055775122857994575 corr: 0.98095703125
  batch 1344 loss: 0.06610560890112538 corr: 0.97412109375
  batch 1408 loss: 0.04536457973335928 corr: 0.98388671875
  batch 1472 loss: 0.04282919653269346 corr: 0.98681640625
  batch 1536 loss: 0.04839409862688626 corr: 0.98388671875
  batch 1600 loss: 0.048696647289034445 corr: 0.97802734375
  batch 1664 loss: 0.05796212264613132 corr: 0.98046875
  batch 1728 loss: 0.04958413962776831 corr: 0.982421875
  batch 1792 loss: 0.06108763825795904 corr: 0.97802734375
  batch 1856 loss: 0.05605244234902784 corr: 0.9794921875
  batch 1920 loss: 0.054464022561660386 corr: 0.9833984375
  batch 1984 loss: 0.06705422396407812 corr: 0.978515625
  batch 2048 loss: 0.05444925369010889 corr: 0.98095703125
LOSS train 0.048034310999858436 valid 0.2524431049823761
MATTHEW CORRELATION train 0.9563242280285036 valid 0.9174107142857143
EPOCH 5:
  batch 64 loss: 0.03493977178186469 corr: 0.990234375
  batch 128 loss: 0.02890270146417606 corr: 0.990234375
  batch 192 loss: 0.016257102598956408 corr: 0.99365234375
  batch 256 loss: 0.023855337587974645 corr: 0.99462890625
  batch 320 loss: 0.02185771753102017 corr: 0.9912109375
  batch 384 loss: 0.028792722593152575 corr: 0.99072265625
  batch 448 loss: 0.02375810270132206 corr: 0.9912109375
  batch 512 loss: 0.03170840622397009 corr: 0.98974609375
  batch 576 loss: 0.03346971358314477 corr: 0.98681640625
  batch 640 loss: 0.03611503212778189 corr: 0.9873046875
  batch 704 loss: 0.041061462288780604 corr: 0.9814453125
  batch 768 loss: 0.028216922270075884 corr: 0.98974609375
  batch 832 loss: 0.027376937907774845 corr: 0.990234375
  batch 896 loss: 0.040116437776759994 corr: 0.98193359375
  batch 960 loss: 0.040175250245738425 corr: 0.986328125
  batch 1024 loss: 0.038609802240898716 corr: 0.98486328125
  batch 1088 loss: 0.053815428571397206 corr: 0.98095703125
  batch 1152 loss: 0.04254124033286644 corr: 0.986328125
  batch 1216 loss: 0.0420106383617167 corr: 0.98486328125
  batch 1280 loss: 0.046628110890196695 corr: 0.984375
  batch 1344 loss: 0.02678534416372713 corr: 0.98974609375
  batch 1408 loss: 0.03642860668878711 corr: 0.9873046875
  batch 1472 loss: 0.0445948134365608 corr: 0.98388671875
  batch 1536 loss: 0.03400567765402229 corr: 0.98779296875
  batch 1600 loss: 0.028499896201537922 corr: 0.9892578125
  batch 1664 loss: 0.04013559841678216 corr: 0.98486328125
  batch 1728 loss: 0.036788160427022376 corr: 0.9873046875
  batch 1792 loss: 0.03987461000087933 corr: 0.98779296875
  batch 1856 loss: 0.0406791938794413 corr: 0.982421875
  batch 1920 loss: 0.045375066218184656 corr: 0.98388671875
  batch 1984 loss: 0.049581702738578315 corr: 0.97900390625
  batch 2048 loss: 0.05060126538955956 corr: 0.982421875
LOSS train 0.03507257080990865 valid 0.2591519355773926
MATTHEW CORRELATION train 0.9602286223277909 valid 0.9252232142857143
EPOCH 6:
  batch 64 loss: 0.022020289208739996 corr: 0.994140625
  batch 128 loss: 0.026968037407641532 corr: 0.98828125
  batch 192 loss: 0.026684098688519953 corr: 0.9912109375
  batch 256 loss: 0.028766829139385663 corr: 0.9892578125
  batch 320 loss: 0.031021325534311472 corr: 0.98779296875
  batch 384 loss: 0.029382701324720983 corr: 0.98876953125
  batch 448 loss: 0.023517689571235678 corr: 0.99169921875
  batch 512 loss: 0.031111714038161153 corr: 0.986328125
  batch 576 loss: 0.03185876955194544 corr: 0.990234375
  batch 640 loss: 0.02794995818658208 corr: 0.9921875
  batch 704 loss: 0.020843109599354648 corr: 0.9912109375
  batch 768 loss: 0.024956140225185663 corr: 0.9892578125
  batch 832 loss: 0.035944045332144015 corr: 0.9873046875
  batch 896 loss: 0.027432303647856315 corr: 0.99072265625
  batch 960 loss: 0.032239490870779264 corr: 0.98828125
  batch 1024 loss: 0.021203448387495882 corr: 0.990234375
  batch 1088 loss: 0.033007031536271825 corr: 0.984375
  batch 1152 loss: 0.02863219217306323 corr: 0.9873046875
  batch 1216 loss: 0.030540620330612 corr: 0.99169921875
  batch 1280 loss: 0.025923480144683708 corr: 0.99072265625
  batch 1344 loss: 0.03043296195073708 corr: 0.98876953125
  batch 1408 loss: 0.03808324393503426 corr: 0.984375
  batch 1472 loss: 0.03511891843754711 corr: 0.9873046875
  batch 1536 loss: 0.03640684433594288 corr: 0.98681640625
  batch 1600 loss: 0.033595398297620704 corr: 0.98681640625
  batch 1664 loss: 0.02465814292736468 corr: 0.98974609375
  batch 1728 loss: 0.021238411093690956 corr: 0.990234375
  batch 1792 loss: 0.03672050899831447 corr: 0.986328125
  batch 1856 loss: 0.04095602503821283 corr: 0.98583984375
  batch 1920 loss: 0.03489534965592611 corr: 0.986328125
  batch 1984 loss: 0.034278224982244865 corr: 0.986328125
  batch 2048 loss: 0.03975051866018475 corr: 0.9833984375
LOSS train 0.02937426160833098 valid 0.33098462224006653
MATTHEW CORRELATION train 0.9617725653206651 valid 0.9095982142857143
EPOCH 7:
  batch 64 loss: 0.03118108603212022 corr: 0.98681640625
  batch 128 loss: 0.012708142399333155 corr: 0.99365234375
  batch 192 loss: 0.019343876999073473 corr: 0.9931640625
  batch 256 loss: 0.024786611678337067 corr: 0.99365234375
  batch 320 loss: 0.02926740200655331 corr: 0.9921875
  batch 384 loss: 0.021113415690251713 corr: 0.9912109375
  batch 448 loss: 0.02322683256033997 corr: 0.9921875
  batch 512 loss: 0.013879870910614045 corr: 0.99462890625
  batch 576 loss: 0.02329925156595891 corr: 0.9912109375
  batch 640 loss: 0.025671492852325173 corr: 0.98876953125
  batch 704 loss: 0.021635096329191583 corr: 0.99365234375
  batch 768 loss: 0.0200054355100292 corr: 0.9921875
  batch 832 loss: 0.01975113329785927 corr: 0.99365234375
  batch 896 loss: 0.016027495601974806 corr: 0.99365234375
  batch 960 loss: 0.034890500834990235 corr: 0.9873046875
  batch 1024 loss: 0.02338061225304955 corr: 0.9912109375
  batch 1088 loss: 0.036947980665900104 corr: 0.9873046875
  batch 1152 loss: 0.022609662793001917 corr: 0.9921875
  batch 1216 loss: 0.01779118204626684 corr: 0.9931640625
  batch 1280 loss: 0.02050372195935779 corr: 0.994140625
  batch 1344 loss: 0.025757853291452193 corr: 0.98974609375
  batch 1408 loss: 0.028415944812650196 corr: 0.98876953125
  batch 1472 loss: 0.02065331673725268 corr: 0.99365234375
  batch 1536 loss: 0.01679806270544759 corr: 0.9951171875
  batch 1600 loss: 0.02709130556559103 corr: 0.9912109375
  batch 1664 loss: 0.027277693932774127 corr: 0.9892578125
  batch 1728 loss: 0.033703115371281456 corr: 0.986328125
  batch 1792 loss: 0.02929533835140319 corr: 0.98779296875
  batch 1856 loss: 0.025875886822177563 corr: 0.99072265625
  batch 1920 loss: 0.0241091428101754 corr: 0.9912109375
  batch 1984 loss: 0.04272986877867879 corr: 0.9873046875
  batch 2048 loss: 0.02362826445732935 corr: 0.9892578125
LOSS train 0.02381701769494322 valid 0.36544176936149597
MATTHEW CORRELATION train 0.9642963182897862 valid 0.890625
EPOCH 8:
  batch 64 loss: 0.011566206115276145 corr: 0.99609375
  batch 128 loss: 0.010177082708651142 corr: 0.9951171875
  batch 192 loss: 0.017078110768125043 corr: 0.9931640625
  batch 256 loss: 0.016513270988298245 corr: 0.99462890625
  batch 320 loss: 0.01987643086249591 corr: 0.990234375
  batch 384 loss: 0.020848225757845285 corr: 0.9912109375
  batch 448 loss: 0.02175805870183467 corr: 0.9921875
  batch 512 loss: 0.026234285778627964 corr: 0.9873046875
  batch 576 loss: 0.02027426782206021 corr: 0.99365234375
  batch 640 loss: 0.02063331980480143 corr: 0.994140625
  batch 704 loss: 0.031120147124966024 corr: 0.98681640625
  batch 768 loss: 0.019038642079976853 corr: 0.99365234375
  batch 832 loss: 0.015854805193157517 corr: 0.99462890625
  batch 896 loss: 0.020456261861909297 corr: 0.99169921875
  batch 960 loss: 0.009763454640733471 corr: 0.99609375
  batch 1024 loss: 0.028732741451676702 corr: 0.99072265625
  batch 1088 loss: 0.02567160840771976 corr: 0.98974609375
  batch 1152 loss: 0.017004711481376944 corr: 0.99365234375
  batch 1216 loss: 0.020595394754650442 corr: 0.99365234375
  batch 1280 loss: 0.022317520454407713 corr: 0.98828125
  batch 1344 loss: 0.021662641348143552 corr: 0.99072265625
  batch 1408 loss: 0.02071944225895095 corr: 0.99267578125
  batch 1472 loss: 0.01935560781885215 corr: 0.9931640625
  batch 1536 loss: 0.01983845965173714 corr: 0.9931640625
  batch 1600 loss: 0.0236900135482756 corr: 0.9921875
  batch 1664 loss: 0.022442106808284734 corr: 0.99169921875
  batch 1728 loss: 0.022866356755457673 corr: 0.99169921875
  batch 1792 loss: 0.02993484204739616 corr: 0.9912109375
  batch 1856 loss: 0.01626125708753534 corr: 0.99462890625
  batch 1920 loss: 0.017120955628115553 corr: 0.9921875
  batch 1984 loss: 0.02188931071486877 corr: 0.9931640625
  batch 2048 loss: 0.036539411170451785 corr: 0.98779296875
LOSS train 0.020304720618615796 valid 0.41503363847732544
MATTHEW CORRELATION train 0.9653503562945368 valid 0.8984375
EPOCH 9:
  batch 64 loss: 0.00843880620368509 corr: 0.99755859375
  batch 128 loss: 0.01578249879003124 corr: 0.99462890625
  batch 192 loss: 0.015939437049382832 corr: 0.9951171875
  batch 256 loss: 0.017992158851711793 corr: 0.9951171875
  batch 320 loss: 0.01217972480071694 corr: 0.99560546875
  batch 384 loss: 0.024178492321880185 corr: 0.99072265625
  batch 448 loss: 0.016232369568569993 corr: 0.99462890625
  batch 512 loss: 0.01365468421499827 corr: 0.99462890625
  batch 576 loss: 0.015305319284721008 corr: 0.99462890625
  batch 640 loss: 0.02331593634175988 corr: 0.99365234375
  batch 704 loss: 0.017549683899005686 corr: 0.99462890625
  batch 768 loss: 0.017327044919966283 corr: 0.99462890625
  batch 832 loss: 0.014200361037410403 corr: 0.9951171875
  batch 896 loss: 0.0156427801209702 corr: 0.994140625
  batch 960 loss: 0.011197017950280497 corr: 0.9951171875
  batch 1024 loss: 0.02360805610078387 corr: 0.9921875
  batch 1088 loss: 0.011722036505489086 corr: 0.99462890625
  batch 1152 loss: 0.017221353927538985 corr: 0.99462890625
  batch 1216 loss: 0.02197004705863037 corr: 0.9912109375
  batch 1280 loss: 0.013482580309869263 corr: 0.9951171875
  batch 1344 loss: 0.018155259300442594 corr: 0.99560546875
  batch 1408 loss: 0.025934492730357306 corr: 0.98876953125
  batch 1472 loss: 0.024882444963168382 corr: 0.98828125
  batch 1536 loss: 0.018439081641986377 corr: 0.99169921875
  batch 1600 loss: 0.018313463626668636 corr: 0.994140625
  batch 1664 loss: 0.01780438493233305 corr: 0.99609375
  batch 1728 loss: 0.024524492360342265 corr: 0.99267578125
  batch 1792 loss: 0.030855074743158184 corr: 0.99072265625
  batch 1856 loss: 0.02296299123099743 corr: 0.9912109375
  batch 1920 loss: 0.014957440627995311 corr: 0.994140625
  batch 1984 loss: 0.024228755575450123 corr: 0.990234375
  batch 2048 loss: 0.022949971982598072 corr: 0.99462890625
LOSS train 0.017967072470434952 valid 0.304501473903656
MATTHEW CORRELATION train 0.9667161520190024 valid 0.921875
EPOCH 10:
  batch 64 loss: 0.015406449602778594 corr: 0.99462890625
  batch 128 loss: 0.01361091289641081 corr: 0.99609375
  batch 192 loss: 0.01822112616036975 corr: 0.99462890625
  batch 256 loss: 0.00822920682799122 corr: 0.99609375
  batch 320 loss: 0.015523526358265372 corr: 0.99609375
  batch 384 loss: 0.02121821721834749 corr: 0.9931640625
  batch 448 loss: 0.016993605217976437 corr: 0.994140625
  batch 512 loss: 0.01471054065473254 corr: 0.99560546875
  batch 576 loss: 0.010291789271832386 corr: 0.9970703125
  batch 640 loss: 0.03067546465729265 corr: 0.99072265625
  batch 704 loss: 0.014633479876238198 corr: 0.994140625
  batch 768 loss: 0.010009873617718767 corr: 0.99560546875
  batch 832 loss: 0.017911894575263432 corr: 0.99267578125
  batch 896 loss: 0.010298364506752478 corr: 0.99609375
  batch 960 loss: 0.029722180968747125 corr: 0.98779296875
  batch 1024 loss: 0.015732014728996546 corr: 0.99365234375
  batch 1088 loss: 0.023821290583327936 corr: 0.99169921875
  batch 1152 loss: 0.025363962493429426 corr: 0.99267578125
  batch 1216 loss: 0.01608886725330194 corr: 0.9931640625
  batch 1280 loss: 0.01555088378563596 corr: 0.9931640625
  batch 1344 loss: 0.01668798255832371 corr: 0.9931640625
  batch 1408 loss: 0.016525456756539825 corr: 0.9931640625
  batch 1472 loss: 0.022060923873823413 corr: 0.99267578125
  batch 1536 loss: 0.013099706454795523 corr: 0.99365234375
  batch 1600 loss: 0.016966333322557148 corr: 0.9931640625
  batch 1664 loss: 0.018131835761778348 corr: 0.9931640625
  batch 1728 loss: 0.01432618407989139 corr: 0.99609375
  batch 1792 loss: 0.026177288558756118 corr: 0.99072265625
  batch 1856 loss: 0.026979521744124213 corr: 0.9892578125
  batch 1920 loss: 0.013526137039207242 corr: 0.994140625
  batch 1984 loss: 0.014664447795667002 corr: 0.9931640625
  batch 2048 loss: 0.023265030660468256 corr: 0.99072265625
LOSS train 0.01722145747796952 valid 0.45788928866386414
MATTHEW CORRELATION train 0.9665973871733967 valid 0.9084821428571429
