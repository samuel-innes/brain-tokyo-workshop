filename log/cola_train.pepg.4.256.best.json
model size 975
cola_started
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
loading file log/cola_train.pepg.4.256.best.json
0 [0.4844963481143165]
1 [0.43161752119863633]
2 [0.43652903569470564]
3 [0.4666020935963667]
4 [0.4446447248410154]
5 [0.49286736671578524]
6 [0.4315371051665201]
7 [0.42949252296080914]
8 [0.44531486355819566]
9 [0.4411159008857727]
10 [0.4425067804162157]
11 [0.439445493609131]
12 [0.43962091416373017]
13 [0.5042780790141805]
14 [0.3848618244444495]
15 [0.5002898712102722]
16 [0.4470397081613558]
17 [0.3962580916743218]
18 [0.4484995944849979]
19 [0.4547375154390805]
20 [0.43612479906517376]
21 [0.45143428975633265]
22 [0.4089839467337759]
23 [0.4009746956442411]
24 [0.43544077696207567]
25 [0.4468424129981643]
26 [0.45374741158591636]
27 [0.4575488743409533]
28 [0.4370027489536955]
29 [0.42450145952345475]
30 [0.40384671135462297]
31 [0.42682939764489203]
32 [0.4400258656952527]
33 [0.4205272670252741]
34 [0.43276738057230046]
35 [0.4401505067427805]
36 [0.5299016135354608]
37 [0.4151037049708309]
38 [0.4444706562658169]
39 [0.47840444111899805]
40 [0.44741833991490954]
41 [0.47918820646719]
42 [0.42691290197963655]
43 [0.47970657897198266]
44 [0.46994054823790776]
45 [0.44277237560276916]
46 [0.5015826273047099]
47 [0.47152098240268153]
48 [0.4496984839828344]
49 [0.39579721415805164]
50 [0.43795449807792564]
51 [0.45365193828227407]
52 [0.44319958700880335]
53 [0.4139439865206026]
54 [0.427188834409435]
55 [0.44091007683754213]
56 [0.45868445692884324]
57 [0.43860149462074705]
58 [0.5141388766432974]
59 [0.4316130328428754]
60 [0.4656541546876414]
61 [0.40702182267065123]
62 [0.4594923689811794]
63 [0.4381311636968924]
64 [0.4254090829914719]
65 [0.4198486985515827]
66 [0.4087017716124191]
67 [0.45526092560049036]
68 [0.45573421500367517]
69 [0.44814685536216925]
70 [0.4591679874318143]
71 [0.45868950701575917]
72 [0.42247866388756417]
73 [0.5190754841052037]
74 [0.42474780379158]
75 [0.5002345849488283]
76 [0.44959916041050674]
77 [0.4823447565378782]
78 [0.4909709894230273]
79 [0.44881265616833793]
80 [0.46968499584675844]
81 [0.4862028466913853]
82 [0.4633502128276347]
83 [0.40760020379575707]
84 [0.4323112288553878]
85 [0.4373800123689244]
86 [0.4346669413728716]
87 [0.45281524809232976]
88 [0.4488689181545629]
89 [0.4125330860425742]
90 [0.3862459532936065]
91 [0.44912036733432803]
92 [0.4408570249384213]
93 [0.4309983282388424]
94 [0.40224138413946586]
95 [0.3684050622351757]
96 [0.42640845664062177]
97 [0.4061826723364328]
98 [0.4648514409212768]
99 [0.45374293254216236]
seed 0 average_reward 0.44484799326582086 standard_deviation 0.02958423924132133
