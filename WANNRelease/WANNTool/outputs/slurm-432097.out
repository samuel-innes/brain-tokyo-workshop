size of model 514
We are executing on: cuda:0
('Backpropagation optimization started',)
EPOCH 1:
  batch 64 loss: 0.556565972045064 corr: 0.20044156453616618
  batch 128 loss: 0.4601636463776231 corr: 0.4568791288699879
  batch 192 loss: 0.44529735133983195 corr: 0.5092463958900992
  batch 256 loss: 0.45266263117082417 corr: 0.506546612051053
LOSS train 0.45723930768557447 valid 0.41481319069862366
MATTHEW CORRELATION train 0.3995495406202523 valid 0.5466548378235284
EPOCH 2:
  batch 64 loss: 0.28057022381108254 corr: 0.7395632094181731
  batch 128 loss: 0.2783352229744196 corr: 0.7143267267378125
  batch 192 loss: 0.27275670738890767 corr: 0.7345892115119846
  batch 256 loss: 0.296825967496261 corr: 0.6873973004897909
LOSS train 0.26948970069747363 valid 0.529411792755127
MATTHEW CORRELATION train 0.6867764652317042 valid 0.5186519611100021
EPOCH 3:
  batch 64 loss: 0.14591593656223267 corr: 0.8786375959084771
  batch 128 loss: 0.13676703165401705 corr: 0.8734535895316771
  batch 192 loss: 0.1550709853763692 corr: 0.8527437944042222
  batch 256 loss: 0.1634072502492927 corr: 0.84106418306338
LOSS train 0.14356088449956098 valid 0.5100038051605225
MATTHEW CORRELATION train 0.8229012926346881 valid 0.5736723181466667
EPOCH 4:
  batch 64 loss: 0.09640261949971318 corr: 0.9294924303632361
  batch 128 loss: 0.0955060097767273 corr: 0.9305513169816615
  batch 192 loss: 0.09710059277858818 corr: 0.9199738357983349
  batch 256 loss: 0.10291056240384933 corr: 0.9159244667006855
LOSS train 0.09359278434838877 valid 0.6472761034965515
MATTHEW CORRELATION train 0.8826130268283983 valid 0.5442329424467984
EPOCH 5:
  batch 64 loss: 0.05913997288735118 corr: 0.9541393209252397
  batch 128 loss: 0.06894838841253659 corr: 0.9390916551338437
  batch 192 loss: 0.06264019322406966 corr: 0.9445666918595029
  batch 256 loss: 0.0785681546331034 corr: 0.9262960109755004
LOSS train 0.06430966188825334 valid 0.6747450232505798
MATTHEW CORRELATION train 0.8988880427209759 valid 0.5581549095901274
EPOCH 6:
  batch 64 loss: 0.049133051637909375 corr: 0.9663146282889774
  batch 128 loss: 0.06239945363631705 corr: 0.9504234619703085
  batch 192 loss: 0.06460645796323661 corr: 0.952541099160634
  batch 256 loss: 0.05637495076371124 corr: 0.9518360060504815
LOSS train 0.05552571080625057 valid 0.9333157539367676
MATTHEW CORRELATION train 0.9125051213063645 valid 0.5218364124705234
EPOCH 7:
  batch 64 loss: 0.03450109914774657 corr: 0.969662334041275
  batch 128 loss: 0.031202894685520732 corr: 0.9766529951195129
  batch 192 loss: 0.053580069783492945 corr: 0.9507532294493315
  batch 256 loss: 0.0448111264504405 corr: 0.9600972418088557
LOSS train 0.03918691106082406 valid 0.8811487555503845
MATTHEW CORRELATION train 0.921114220995576 valid 0.5401273139804856
EPOCH 8:
  batch 64 loss: 0.03754828243654629 corr: 0.9758246696483185
  batch 128 loss: 0.03418891982255445 corr: 0.969755087828205
  batch 192 loss: 0.03431721468223259 corr: 0.9722194722016989
  batch 256 loss: 0.052608147387218196 corr: 0.9572465297930023
LOSS train 0.03788956760084813 valid 0.7670121788978577
MATTHEW CORRELATION train 0.9253840619632775 valid 0.5416012616384244
EPOCH 9:
  batch 64 loss: 0.019899001919839066 corr: 0.9856413819487128
  batch 128 loss: 0.03709907907250454 corr: 0.9693060322417909
  batch 192 loss: 0.03165547963726567 corr: 0.9761241281087216
  batch 256 loss: 0.041232489495087066 corr: 0.9729474315705835
LOSS train 0.031017564208882707 valid 0.7435383796691895
MATTHEW CORRELATION train 0.9323030385360737 valid 0.5509615728685678
EPOCH 10:
  batch 64 loss: 0.018953669368784176 corr: 0.9822626737936618
  batch 128 loss: 0.024364987501030555 corr: 0.9759937360389077
  batch 192 loss: 0.035866032968442596 corr: 0.9733784422991105
  batch 256 loss: 0.04855491594207706 corr: 0.9556040488933709
LOSS train 0.030504980484855972 valid 0.7798124551773071
MATTHEW CORRELATION train 0.9282958569612062 valid 0.5129999504422714
