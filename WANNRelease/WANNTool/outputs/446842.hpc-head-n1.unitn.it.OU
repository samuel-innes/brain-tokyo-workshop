filename log/cola.pepg.4.128.best.json
model size 975
cola_started
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
loading file log/cola.pepg.4.128.best.json
0 [0.33354607980585316]
1 [0.33784371357627047]
2 [0.2978007783521618]
3 [0.3532972460940057]
4 [0.30725085027406407]
5 [0.38148817052709666]
6 [0.34675735133377955]
7 [0.29234883744266665]
8 [0.3403506238761556]
9 [0.3292531240922879]
10 [0.3310144877794378]
11 [0.32282239535504964]
12 [0.28880496793944843]
13 [0.3475299393741122]
14 [0.2691995402176427]
15 [0.37577030139902684]
16 [0.38447000562638345]
17 [0.29616219003855104]
18 [0.3361956064460955]
19 [0.34438477725053374]
20 [0.3513611367800208]
21 [0.36439047788545303]
22 [0.34431738462894257]
23 [0.28144379653096546]
24 [0.38004311748189995]
25 [0.33066990956360826]
26 [0.3237477336563127]
27 [0.3591475271562078]
28 [0.28303634537320177]
29 [0.3172206342872592]
30 [0.3506578350675719]
31 [0.3396239465660966]
32 [0.3127968107134532]
33 [0.3232712721278882]
34 [0.2916526592697451]
35 [0.31928711229647255]
36 [0.35965099143107665]
37 [0.3164052677326654]
38 [0.29691982252402105]
39 [0.3261481216274196]
40 [0.3263075969515005]
41 [0.36777974822654114]
42 [0.2953430038642978]
43 [0.3485851562343824]
44 [0.3281577692821001]
45 [0.33500426419244544]
46 [0.40628853106968454]
47 [0.34824568945181494]
48 [0.34333389352908333]
49 [0.30325027480635686]
50 [0.3010615288050203]
51 [0.31458449575707553]
52 [0.3490680789226125]
53 [0.32956843173703476]
54 [0.31874183920618554]
55 [0.31667854391884775]
56 [0.3184727839192837]
57 [0.32450530687849916]
58 [0.391160687485124]
59 [0.33020191290214457]
60 [0.3764051905650621]
61 [0.2701721560996913]
62 [0.36754212132124514]
63 [0.332688049179789]
64 [0.3507397346355194]
65 [0.2710077883796474]
66 [0.2825803912591316]
67 [0.33470581787662207]
68 [0.3024913806140437]
69 [0.33079335052312303]
70 [0.3308779387300281]
71 [0.3165837218001556]
72 [0.30600140456263825]
73 [0.34403251949609065]
74 [0.32669732406531327]
75 [0.3803932572610431]
76 [0.3386980266010337]
77 [0.3791055192847197]
78 [0.37053132976521963]
79 [0.3336786179970694]
80 [0.35518802222920154]
81 [0.35605937118789305]
82 [0.34495574151478037]
83 [0.29376073242171447]
84 [0.2894030403020696]
85 [0.3524361048564905]
86 [0.3189121602381842]
87 [0.33703536931915623]
88 [0.29642384760553936]
89 [0.313450711720758]
90 [0.2849150095824951]
91 [0.3515103912472572]
92 [0.37644878619300776]
93 [0.361366590508512]
94 [0.29141881194997166]
95 [0.25910347506471165]
96 [0.3238957256529294]
97 [0.32653340600291675]
98 [0.392738799527839]
99 [0.3732426081658819]
seed 0 average_reward 0.33128946771949436 standard_deviation 0.030867035923587863
