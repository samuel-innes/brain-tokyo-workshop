filename log/cola_train.pepg.4.512.best.json
model size 514
cola_started
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
loading file log/cola_train.pepg.4.512.best.json
0 [0.4618026958644064]
1 [0.39155501347735927]
2 [0.4187477015339996]
3 [0.43775484271712084]
4 [0.44442199140602223]
5 [0.45553838334827035]
6 [0.41336964207971816]
7 [0.4075616655194865]
8 [0.4468039296051337]
9 [0.4446887314214045]
10 [0.46425909361955875]
11 [0.41114656229207475]
12 [0.3785029826531992]
13 [0.4510879376241017]
14 [0.37597070338620675]
15 [0.48014321907672536]
16 [0.46605652493939115]
17 [0.42683556844705844]
18 [0.39614919498705814]
19 [0.4518886311704042]
20 [0.4302341118318536]
21 [0.42691290197963677]
22 [0.3585903124423121]
23 [0.39065946466821294]
24 [0.403160745578252]
25 [0.4213611723504084]
26 [0.4272546577762257]
27 [0.4574766384521566]
28 [0.3585455178149109]
29 [0.4265053635816446]
30 [0.41787912022034746]
31 [0.40925067687147926]
32 [0.4173907947725029]
33 [0.4294597406111815]
34 [0.4502217231586642]
35 [0.42347131394430865]
36 [0.45017310945125005]
37 [0.3940397289599709]
38 [0.41164812421962466]
39 [0.4618718663857041]
40 [0.46697413030125945]
41 [0.462164187013389]
42 [0.4143790621701895]
43 [0.5018544637316824]
44 [0.4482084221931382]
45 [0.38995136310777295]
46 [0.4818752413279416]
47 [0.47405874936762776]
48 [0.4125037268361423]
49 [0.3622986139033588]
50 [0.4487297773104798]
51 [0.40718231614741285]
52 [0.4597782052872705]
53 [0.42354421718087465]
54 [0.3886053191215568]
55 [0.47526979979906797]
56 [0.4414175394648438]
57 [0.4167137278978277]
58 [0.497152137965815]
59 [0.39357194419896785]
60 [0.4336797308399578]
61 [0.41201256593715463]
62 [0.45858612851848585]
63 [0.42310673918034997]
64 [0.44120654164632234]
65 [0.394553359383182]
66 [0.40843614639324616]
67 [0.44850372485094264]
68 [0.4113944919943904]
69 [0.4034138075175004]
70 [0.4135372342975053]
71 [0.4219774103834881]
72 [0.4117953557681381]
73 [0.4884845926540735]
74 [0.4497755739750447]
75 [0.4652066572815762]
76 [0.38872465401738404]
77 [0.4744629211627892]
78 [0.452950546161964]
79 [0.41585345365952187]
80 [0.4650614530570553]
81 [0.47455492990068543]
82 [0.4303982786938997]
83 [0.41665623112310807]
84 [0.4098115092765656]
85 [0.43390889695724594]
86 [0.4100413392217111]
87 [0.4540510446547147]
88 [0.4336307280132795]
89 [0.3849822787723198]
90 [0.39111810485621185]
91 [0.448017919657144]
92 [0.4251590547683618]
93 [0.4428939001158739]
94 [0.41726257459081967]
95 [0.3370284682071037]
96 [0.3701929371064067]
97 [0.3816866286210231]
98 [0.45345033293390513]
99 [0.4503823075253807]
seed 0 average_reward 0.42804575598241806 standard_deviation 0.032416371231352416
